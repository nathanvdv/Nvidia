{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>difficulty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Le test de niveau en français est sur le site ...</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sentence difficulty\n",
       "0   0  Les coûts kilométriques réels peuvent diverger...         C1\n",
       "1   1  Le bleu, c'est ma couleur préférée mais je n'a...         A1\n",
       "2   2  Le test de niveau en français est sur le site ...         A1\n",
       "3   3           Est-ce que ton mari est aussi de Boston?         A1\n",
       "4   4  Dans les écoles de commerce, dans les couloirs...         B1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reload the dataset\n",
    "training_data = pd.read_csv('/home/nathan/OneDrive/GitHub/Nvidia/Data/training_data.csv')\n",
    "\n",
    "# Check for missing values and basic statistics\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "2023-11-19 15:46:09.543810: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-19 15:46:09.543856: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-19 15:46:09.546057: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-19 15:46:09.558157: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-19 15:46:11.168881: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-19 15:46:13.136632: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>cleaned_sentence</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
       "      <td>C1</td>\n",
       "      <td>les coûts kilométriques réels peuvent diverger...</td>\n",
       "      <td>247</td>\n",
       "      <td>38</td>\n",
       "      <td>[DET, NOUN, ADJ, ADJ, VERB, VERB, ADV, ADP, NO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
       "      <td>A1</td>\n",
       "      <td>le bleu cest ma couleur préférée mais je naime...</td>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "      <td>[DET, NOUN, VERB, DET, NOUN, VERB, CCONJ, PRON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Le test de niveau en français est sur le site ...</td>\n",
       "      <td>A1</td>\n",
       "      <td>le test de niveau en français est sur le site ...</td>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "      <td>[DET, NOUN, ADP, NOUN, ADP, NOUN, VERB, ADP, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
       "      <td>A1</td>\n",
       "      <td>estce que ton mari est aussi de boston</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>[NOUN, SCONJ, PROPN, NOUN, AUX, ADV, ADP, PROPN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
       "      <td>B1</td>\n",
       "      <td>dans les écoles de commerce dans les couloirs ...</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>[ADP, DET, NOUN, ADP, NOUN, ADP, DET, NOUN, AD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sentence difficulty  \\\n",
       "0   0  Les coûts kilométriques réels peuvent diverger...         C1   \n",
       "1   1  Le bleu, c'est ma couleur préférée mais je n'a...         A1   \n",
       "2   2  Le test de niveau en français est sur le site ...         A1   \n",
       "3   3           Est-ce que ton mari est aussi de Boston?         A1   \n",
       "4   4  Dans les écoles de commerce, dans les couloirs...         B1   \n",
       "\n",
       "                                    cleaned_sentence  sentence_length  \\\n",
       "0  les coûts kilométriques réels peuvent diverger...              247   \n",
       "1  le bleu cest ma couleur préférée mais je naime...               58   \n",
       "2  le test de niveau en français est sur le site ...               64   \n",
       "3             estce que ton mari est aussi de boston               38   \n",
       "4  dans les écoles de commerce dans les couloirs ...              200   \n",
       "\n",
       "   word_count                                           pos_tags  \n",
       "0          38  [DET, NOUN, ADJ, ADJ, VERB, VERB, ADV, ADP, NO...  \n",
       "1          12  [DET, NOUN, VERB, DET, NOUN, VERB, CCONJ, PRON...  \n",
       "2          13  [DET, NOUN, ADP, NOUN, ADP, NOUN, VERB, ADP, D...  \n",
       "3           8   [NOUN, SCONJ, PROPN, NOUN, AUX, ADV, ADP, PROPN]  \n",
       "4          32  [ADP, DET, NOUN, ADP, NOUN, ADP, DET, NOUN, AD...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import spacy\n",
    "\n",
    "# Load the French language model for spaCy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "# Text Cleaning Function\n",
    "def clean_text(text):\n",
    "    # Lowercasing the text\n",
    "    text = text.lower()\n",
    "    # Removing punctuations\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Removing numbers and other non-letter characters\n",
    "    text = re.sub(r'[^a-zàâçéèêëîïôûùüÿñæœ]', ' ', text)\n",
    "    return text\n",
    "\n",
    "# POS Tagging Function\n",
    "def pos_tagging(text):\n",
    "    doc = nlp(text)\n",
    "    pos_tags = [token.pos_ for token in doc]\n",
    "    return pos_tags\n",
    "\n",
    "# Applying the cleaning function to the dataset\n",
    "training_data['cleaned_sentence'] = training_data['sentence'].apply(clean_text)\n",
    "\n",
    "# Feature Engineering\n",
    "# Adding sentence length and word count\n",
    "training_data['sentence_length'] = training_data['cleaned_sentence'].apply(len)\n",
    "training_data['word_count'] = training_data['cleaned_sentence'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Adding POS tagging\n",
    "training_data['pos_tags'] = training_data['cleaned_sentence'].apply(pos_tagging)\n",
    "\n",
    "# Displaying the first few rows of the updated dataset\n",
    "training_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Statistical Analysis of Sentence Features\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Grouping by difficulty level and calculating mean and standard deviation\n",
    "grouped_data = training_data.groupby('difficulty').agg({'sentence_length': ['mean', 'std'], 'word_count': ['mean', 'std']}).reset_index()\n",
    "\n",
    "# Plotting the sentence length and word count for each difficulty level\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot for Sentence Length\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x='difficulty', y=('sentence_length', 'mean'), data=grouped_data)\n",
    "plt.title('Average Sentence Length by Difficulty Level')\n",
    "\n",
    "# Plot for Word Count\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x='difficulty', y=('word_count', 'mean'), data=grouped_data)\n",
    "plt.title('Average Word Count by Difficulty Level')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   id                                           sentence difficulty  \\\n",
       " 0   0  Les coûts kilométriques réels peuvent diverger...         C1   \n",
       " 1   1  Le bleu, c'est ma couleur préférée mais je n'a...         A1   \n",
       " 2   2  Le test de niveau en français est sur le site ...         A1   \n",
       " 3   3           Est-ce que ton mari est aussi de Boston?         A1   \n",
       " 4   4  Dans les écoles de commerce, dans les couloirs...         B1   \n",
       " \n",
       "                                     cleaned_sentence  sentence_length  \\\n",
       " 0  les coûts kilométriques réels peuvent diverger...              247   \n",
       " 1  le bleu cest ma couleur préférée mais je naime...               58   \n",
       " 2  le test de niveau en français est sur le site ...               64   \n",
       " 3             estce que ton mari est aussi de boston               38   \n",
       " 4  dans les écoles de commerce dans les couloirs ...              200   \n",
       " \n",
       "    word_count                                           pos_tags  \\\n",
       " 0          38  [DET, NOUN, ADJ, ADJ, VERB, VERB, ADV, ADP, NO...   \n",
       " 1          12  [DET, NOUN, VERB, DET, NOUN, VERB, CCONJ, PRON...   \n",
       " 2          13  [DET, NOUN, ADP, NOUN, ADP, NOUN, VERB, ADP, D...   \n",
       " 3           8   [NOUN, SCONJ, PROPN, NOUN, AUX, ADV, ADP, PROPN]   \n",
       " 4          32  [ADP, DET, NOUN, ADP, NOUN, ADP, DET, NOUN, AD...   \n",
       " \n",
       "    difficulty_encoded  \n",
       " 0                   4  \n",
       " 1                   0  \n",
       " 2                   0  \n",
       " 3                   0  \n",
       " 4                   2  ,\n",
       " array(['A1', 'A2', 'B1', 'B2', 'C1', 'C2'], dtype=object))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the difficulty levels\n",
    "from sklearn.calibration import LabelEncoder\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "training_data['difficulty_encoded'] = label_encoder.fit_transform(training_data['difficulty'])\n",
    "\n",
    "# Display the first few rows of the modified dataframe\n",
    "df_encoded_head = training_data.head()\n",
    "encoded_classes = label_encoder.classes_\n",
    "\n",
    "df_encoded_head, encoded_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 min +-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CamembertTokenizer, CamembertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "model = CamembertModel.from_pretrained(\"camembert-base\")\n",
    "\n",
    "# Function to encode sentences in batches\n",
    "def encode_sentences_in_batches(sentences, batch_size=64):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    batched_embeddings = []\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch_sentences = sentences[i:i + batch_size]\n",
    "        inputs = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "        batched_embeddings.append(embeddings)\n",
    "\n",
    "    return np.vstack(batched_embeddings)\n",
    "\n",
    "# Tokenize and encode sentences in batches\n",
    "encoded_sentences = encode_sentences_in_batches(training_data['sentence'].tolist())\n",
    "\n",
    "# Use encoded_sentences for training the logistic regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.07098451  0.09660295  0.03961487 ... -0.19470686  0.0024913\n",
      "  -0.03617467]\n",
      " [-0.05412755 -0.06828036  0.03988926 ... -0.10792161 -0.00187612\n",
      "   0.05180975]\n",
      " [ 0.01214479  0.03654218  0.09464204 ... -0.04433489  0.02998401\n",
      "  -0.01019532]\n",
      " ...\n",
      " [ 0.01033856 -0.03724339  0.1563079  ... -0.03505957  0.02489541\n",
      "  -0.05177126]\n",
      " [ 0.05524175 -0.11483988 -0.00791766 ... -0.20609647  0.08733316\n",
      "   0.02624701]\n",
      " [-0.04218321  0.09089916  0.15073569 ... -0.08180519  0.05069391\n",
      "  -0.00325873]]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_sentences)\n",
    "np.save('/home/nathan/OneDrive/GitHub/Nvidia/Data/encoded_sentences.npy', encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Since we can't extract embeddings here, we'll assume `encoded_sentences` is available\n",
    "# Let's pretend we have a variable encoded_sentences which contains the embeddings\n",
    "encoded_sentences = np.load('/home/nathan/OneDrive/GitHub/Nvidia/Data/encoded_sentences.npy')\n",
    "# Train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(encoded_sentences, training_data['difficulty_encoded'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_regression_model = LogisticRegression(max_iter=1000)\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=11)  # You can tune 'n_neighbors'\n",
    "knn_model.fit(X_train, y_train)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.77      0.71       166\n",
      "           1       0.47      0.51      0.49       158\n",
      "           2       0.51      0.43      0.47       166\n",
      "           3       0.49      0.47      0.48       153\n",
      "           4       0.41      0.41      0.41       152\n",
      "           5       0.56      0.56      0.56       165\n",
      "\n",
      "    accuracy                           0.53       960\n",
      "   macro avg       0.52      0.52      0.52       960\n",
      "weighted avg       0.52      0.53      0.52       960\n",
      "\n",
      "Accuracy: 0.525\n",
      "Confusion Matrix:\n",
      " [[127  30   8   1   0   0]\n",
      " [ 35  80  36   3   2   2]\n",
      " [ 23  49  71  11   6   6]\n",
      " [  4   7  15  72  37  18]\n",
      " [  0   1   5  39  62  45]\n",
      " [  1   3   4  22  43  92]]\n",
      "\n",
      "k-Nearest Neighbors:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.83      0.61       166\n",
      "           1       0.35      0.45      0.40       158\n",
      "           2       0.36      0.26      0.30       166\n",
      "           3       0.48      0.40      0.44       153\n",
      "           4       0.51      0.45      0.48       152\n",
      "           5       0.67      0.39      0.50       165\n",
      "\n",
      "    accuracy                           0.46       960\n",
      "   macro avg       0.48      0.46      0.45       960\n",
      "weighted avg       0.48      0.46      0.45       960\n",
      "\n",
      "Accuracy: 0.4635416666666667\n",
      "Confusion Matrix:\n",
      " [[137  24   5   0   0   0]\n",
      " [ 68  71  16   1   0   2]\n",
      " [ 42  65  43   9   4   3]\n",
      " [ 22  17  24  61  26   3]\n",
      " [  5  10  17  28  68  24]\n",
      " [  8  13  16  28  35  65]]\n",
      "\n",
      "Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.49      0.48       166\n",
      "           1       0.28      0.25      0.27       158\n",
      "           2       0.30      0.31      0.30       166\n",
      "           3       0.30      0.32      0.31       153\n",
      "           4       0.30      0.32      0.31       152\n",
      "           5       0.45      0.41      0.43       165\n",
      "\n",
      "    accuracy                           0.35       960\n",
      "   macro avg       0.35      0.35      0.35       960\n",
      "weighted avg       0.35      0.35      0.35       960\n",
      "\n",
      "Accuracy: 0.35208333333333336\n",
      "Confusion Matrix:\n",
      " [[81 41 22 13  5  4]\n",
      " [43 40 42 17  9  7]\n",
      " [27 35 51 24 17 12]\n",
      " [13 13 22 49 35 21]\n",
      " [ 4  5 18 38 49 38]\n",
      " [ 6  8 15 22 46 68]]\n",
      "\n",
      "Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.70      0.64       166\n",
      "           1       0.40      0.42      0.41       158\n",
      "           2       0.41      0.35      0.38       166\n",
      "           3       0.49      0.50      0.50       153\n",
      "           4       0.46      0.37      0.41       152\n",
      "           5       0.57      0.61      0.59       165\n",
      "\n",
      "    accuracy                           0.49       960\n",
      "   macro avg       0.49      0.49      0.49       960\n",
      "weighted avg       0.49      0.49      0.49       960\n",
      "\n",
      "Accuracy: 0.4947916666666667\n",
      "Confusion Matrix:\n",
      " [[117  34  13   1   1   0]\n",
      " [ 49  67  31   6   3   2]\n",
      " [ 21  49  58  21   6  11]\n",
      " [  8  10  18  77  27  13]\n",
      " [  1   3  10  32  56  50]\n",
      " [  2   5  11  19  28 100]]\n",
      "\n",
      "Support Vector Machine:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.77      0.73       166\n",
      "           1       0.49      0.54      0.52       158\n",
      "           2       0.51      0.43      0.47       166\n",
      "           3       0.49      0.51      0.50       153\n",
      "           4       0.45      0.45      0.45       152\n",
      "           5       0.58      0.53      0.55       165\n",
      "\n",
      "    accuracy                           0.54       960\n",
      "   macro avg       0.54      0.54      0.54       960\n",
      "weighted avg       0.54      0.54      0.54       960\n",
      "\n",
      "Accuracy: 0.5395833333333333\n",
      "Confusion Matrix:\n",
      " [[127  31   6   1   1   0]\n",
      " [ 34  86  34   1   2   1]\n",
      " [ 20  49  72  12   6   7]\n",
      " [  2   6  21  78  32  14]\n",
      " [  0   1   3  38  68  42]\n",
      " [  1   2   6  28  41  87]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Logistic Regression\n",
    "lr_predictions = logistic_regression_model.predict(X_val)\n",
    "print(\"Logistic Regression:\")\n",
    "print(classification_report(y_val, lr_predictions))\n",
    "print(\"Accuracy:\", accuracy_score(y_val, lr_predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, lr_predictions))\n",
    "\n",
    "# k-Nearest Neighbors\n",
    "knn_predictions = knn_model.predict(X_val)\n",
    "print(\"\\nk-Nearest Neighbors:\")\n",
    "print(classification_report(y_val, knn_predictions))\n",
    "print(\"Accuracy:\", accuracy_score(y_val, knn_predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, knn_predictions))\n",
    "\n",
    "# Decision Tree\n",
    "dt_predictions = decision_tree_model.predict(X_val)\n",
    "print(\"\\nDecision Tree:\")\n",
    "print(classification_report(y_val, dt_predictions))\n",
    "print(\"Accuracy:\", accuracy_score(y_val, dt_predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, dt_predictions))\n",
    "\n",
    "# Random Forest\n",
    "rf_predictions = random_forest_model.predict(X_val)\n",
    "print(\"\\nRandom Forest:\")\n",
    "print(classification_report(y_val, rf_predictions))\n",
    "print(\"Accuracy:\", accuracy_score(y_val, rf_predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, rf_predictions))\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_predictions = svm_model.predict(X_val)\n",
    "print(\"\\nSupport Vector Machine:\")\n",
    "print(classification_report(y_val, svm_predictions))\n",
    "print(\"Accuracy:\", accuracy_score(y_val, svm_predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, svm_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained CamemBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4481557a9484b6d9230ef670a016ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 8049.8191, 'train_samples_per_second': 2.385, 'train_steps_per_second': 0.037, 'train_loss': 1.6408092244466146, 'epoch': 4.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "# Custom Dataset Class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "\n",
    "# Prepare the dataset\n",
    "train_dataset = CustomDataset(\n",
    "    texts=training_data['sentence'].to_numpy(),\n",
    "    labels=training_data['difficulty_encoded'].to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=128  # or any other value that suits your needs\n",
    ")\n",
    "\n",
    "# Model for Sequence Classification\n",
    "model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=len(label_encoder.classes_))\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=32,\n",
    "    learning_rate=2e-5,\n",
    "    logging_dir='./logs',\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type='linear',  # Updated value\n",
    "    warmup_steps=500,\n",
    "    gradient_accumulation_steps=2,\n",
    "    max_grad_norm=1.0,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./my_finetuned_camembert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Trainer: evaluation requires an eval_dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/nathan/OneDrive/GitHub/Nvidia/Code/CamemBERT.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/Nvidia/Code/CamemBERT.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m results \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mevaluate()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/Nvidia/Code/CamemBERT.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m results\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:3062\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3059\u001b[0m \u001b[39m# memory metrics - must set up as early as possible\u001b[39;00m\n\u001b[1;32m   3060\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_memory_tracker\u001b[39m.\u001b[39mstart()\n\u001b[0;32m-> 3062\u001b[0m eval_dataloader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_eval_dataloader(eval_dataset)\n\u001b[1;32m   3063\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   3065\u001b[0m eval_loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_loop \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39muse_legacy_prediction_loop \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_loop\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:888\u001b[0m, in \u001b[0;36mTrainer.get_eval_dataloader\u001b[0;34m(self, eval_dataset)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39mReturns the evaluation [`~torch.utils.data.DataLoader`].\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[39m        by the `model.forward()` method are automatically removed. It must implement `__len__`.\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[39mif\u001b[39;00m eval_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTrainer: evaluation requires an eval_dataset.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    889\u001b[0m eval_dataset \u001b[39m=\u001b[39m eval_dataset \u001b[39mif\u001b[39;00m eval_dataset \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_dataset\n\u001b[1;32m    890\u001b[0m data_collator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_collator\n",
      "\u001b[0;31mValueError\u001b[0m: Trainer: evaluation requires an eval_dataset."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>cleaned_sentence</th>\n",
       "      <th>difficulty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Nous dûmes nous excuser des propos que nous eû...</td>\n",
       "      <td>nous dûmes nous excuser des propos que nous eû...</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Vous ne pouvez pas savoir le plaisir que j'ai ...</td>\n",
       "      <td>vous ne pouvez pas savoir le plaisir que jai d...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Et, paradoxalement, boire froid n'est pas la b...</td>\n",
       "      <td>et paradoxalement boire froid nest pas la bonn...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ce n'est pas étonnant, car c'est une saison my...</td>\n",
       "      <td>ce nest pas étonnant car cest une saison mysté...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Le corps de Golo lui-même, d'une essence aussi...</td>\n",
       "      <td>le corps de golo luimême dune essence aussi su...</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sentence  \\\n",
       "0   0  Nous dûmes nous excuser des propos que nous eû...   \n",
       "1   1  Vous ne pouvez pas savoir le plaisir que j'ai ...   \n",
       "2   2  Et, paradoxalement, boire froid n'est pas la b...   \n",
       "3   3  Ce n'est pas étonnant, car c'est une saison my...   \n",
       "4   4  Le corps de Golo lui-même, d'une essence aussi...   \n",
       "\n",
       "                                    cleaned_sentence difficulty  \n",
       "0  nous dûmes nous excuser des propos que nous eû...         C2  \n",
       "1  vous ne pouvez pas savoir le plaisir que jai d...         A2  \n",
       "2  et paradoxalement boire froid nest pas la bonn...         B1  \n",
       "3  ce nest pas étonnant car cest une saison mysté...         A2  \n",
       "4  le corps de golo luimême dune essence aussi su...         C2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model = CamembertForSequenceClassification.from_pretrained(\"./my_finetuned_camembert\")\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "\n",
    "# Load and preprocess the unlabelled test data\n",
    "unlabelled_test_data = pd.read_csv('/home/nathan/OneDrive/GitHub/Nvidia/Data/unlabelled_test_data.csv')\n",
    "unlabelled_test_data['cleaned_sentence'] = unlabelled_test_data['sentence'].apply(clean_text)  # Use your clean_text function\n",
    "\n",
    "# Function to encode and predict labels for sentences\n",
    "def predict_labels(sentences, model, tokenizer, batch_size=64):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch_sentences = sentences[i:i + batch_size]\n",
    "        inputs = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        batch_predictions = torch.argmax(logits, dim=1).numpy()\n",
    "        predictions.extend(batch_predictions)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Predict labels for the unlabelled test data\n",
    "predicted_labels = predict_labels(unlabelled_test_data['cleaned_sentence'].tolist(), model, tokenizer)\n",
    "\n",
    "# Convert numerical labels back to original class names\n",
    "predicted_classes = label_encoder.inverse_transform(predicted_labels)\n",
    "\n",
    "# Adding predictions to the DataFrame\n",
    "unlabelled_test_data['difficulty'] = predicted_classes\n",
    "\n",
    "unlabelled_test_data[['id', 'difficulty']].to_csv('/home/nathan/OneDrive/GitHub/Nvidia/Data/Nvidia_CamemBERT_Enhanched_submission.csv', index=False)\n",
    "\n",
    "# Displaying the predictions\n",
    "unlabelled_test_data.head()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parameter grid\n",
    "param_grid_lr = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "# Model\n",
    "logistic_regression_model = LogisticRegression(max_iter=10)\n",
    "grid_search_lr = GridSearchCV(logistic_regression_model, param_grid_lr, cv=5, scoring='accuracy')\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters for Logistic Regression:\", grid_search_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Parameter grid\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Model\n",
    "svm_model = SVC()\n",
    "grid_search_svm = GridSearchCV(svm_model, param_grid_svm, cv=5, scoring='accuracy')\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters for SVM:\", grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_optimized = LogisticRegression(**grid_search_lr.best_params_)\n",
    "logistic_regression_optimized.fit(X_train, y_train)\n",
    "svm_optimized = SVC(**grid_search_svm.best_params_)\n",
    "svm_optimized.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Evaluate each model\n",
    "models = [logistic_regression_optimized, svm_optimized]\n",
    "model_names = [\"Logistic Regression\", \"SVM\"]\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    predictions = model.predict(X_val)\n",
    "    print(f\"Model: {name}\")\n",
    "    print(classification_report(y_val, predictions))\n",
    "    print(\"Accuracy:\", accuracy_score(y_val, predictions))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unlabeded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_test_data = pd.read_csv('Data/unlabelled_test_data.csv')\n",
    "unlabelled_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CamembertTokenizer, CamembertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "model = CamembertModel.from_pretrained(\"camembert-base\")\n",
    "\n",
    "# Function to encode sentences in batches\n",
    "def encode_sentences(sentences, batch_size=64):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    batched_embeddings = []\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch_sentences = sentences[i:i + batch_size]\n",
    "        inputs = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "        batched_embeddings.append(embeddings)\n",
    "\n",
    "    return np.vstack(batched_embeddings)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the cleaning function to the dataset\n",
    "unlabelled_test_data['cleaned_sentence'] = unlabelled_test_data['sentence'].apply(clean_text)\n",
    "\n",
    "# Feature Engineering\n",
    "# Adding sentence length and word count\n",
    "unlabelled_test_data['sentence_length'] = unlabelled_test_data['cleaned_sentence'].apply(len)\n",
    "unlabelled_test_data['word_count'] = unlabelled_test_data['cleaned_sentence'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Adding POS tagging\n",
    "unlabelled_test_data['pos_tags'] = unlabelled_test_data['cleaned_sentence'].apply(pos_tagging)\n",
    "\n",
    "#encoding data\n",
    "embeddings = encode_sentences(unlabelled_test_data['sentence'].tolist())\n",
    "\n",
    "\n",
    "# Embeddings are now stored in the 'embeddings' variable\n",
    "embeddings.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained CamemBERT predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model = CamembertForSequenceClassification.from_pretrained(\"./my_finetuned_camembert\")\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "\n",
    "# Load the unlabelled test data\n",
    "unlabelled_test_data = pd.read_csv('Data/unlabelled_test_data.csv')\n",
    "\n",
    "# Applying the cleaning function to the dataset (make sure this function is defined in your environment)\n",
    "unlabelled_test_data['cleaned_sentence'] = unlabelled_test_data['sentence'].apply(clean_text)\n",
    "\n",
    "# Function to encode and predict labels for sentences\n",
    "def predict_labels(sentences, model, tokenizer, batch_size=64):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch_sentences = sentences[i:i + batch_size]\n",
    "        inputs = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        batch_predictions = torch.argmax(logits, dim=1).numpy()\n",
    "        predictions.extend(batch_predictions)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Predict labels for the unlabelled test data\n",
    "predicted_labels = predict_labels(unlabelled_test_data['cleaned_sentence'].tolist(), model, tokenizer)\n",
    "\n",
    "# Convert numerical labels back to original class names\n",
    "predicted_classes = label_encoder.inverse_transform(predicted_labels)\n",
    "\n",
    "# Adding predictions to the DataFrame\n",
    "unlabelled_test_data['difficulty'] = predicted_classes\n",
    "\n",
    "# Displaying the predictions\n",
    "unlabelled_test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'id' is the column name for the identifier in your DataFrame\n",
    "# and 'predicted_difficulty' is the column with the predicted difficulty levels\n",
    "\n",
    "# Saving the specified columns to a CSV file\n",
    "unlabelled_test_data[['id', 'difficulty']].to_csv('Data/CamemBERT_pretrained_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert the series of arrays into a 2D NumPy array\n",
    "#unlabeled_test_features_array = np.array([feature for feature in unlabeled_test_features])\n",
    "\n",
    "# Now use the SVM model to make predictions\n",
    "# Ensure unlabeled_test_features_array is in the correct format expected by the SVM model\n",
    "predictions = svm_optimized.predict(embeddings)\n",
    "\n",
    "# Convert Predictions back to Difficulty Labels\n",
    "predicted_difficulties = label_encoder.inverse_transform(predictions)\n",
    "\n",
    "# Step 5: Output the Predictions\n",
    "unlabelled_test_data['difficulty'] = predicted_difficulties\n",
    "unlabelled_test_data[['id', 'difficulty']].to_csv('Data/CamemBERT_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
