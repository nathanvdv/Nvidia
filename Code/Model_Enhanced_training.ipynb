{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the enhanced sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from ast import literal_eval\n",
    "\n",
    "# Load data from CSV files\n",
    "data = pd.read_csv('/home/nathan/OneDrive/GitHub/Nvidia/data/Cleaned_Enhanced_training.csv')\n",
    "test_data = pd.read_csv('/home/nathan/OneDrive/GitHub/Nvidia/data/Cleaned_Enhanced_test.csv')\n",
    "\n",
    "# Convert string representations of lists back to actual lists\n",
    "data['embeddings'] = data['embeddings'].apply(literal_eval)\n",
    "test_data['embeddings'] = test_data['embeddings'].apply(literal_eval)\n",
    "\n",
    "# Flatten the embeddings\n",
    "num_embedding_features = len(data['embeddings'].iloc[0])\n",
    "for i in range(num_embedding_features):\n",
    "    data[f'emb_{i}'] = data['embeddings'].apply(lambda x: x[i])\n",
    "    test_data[f'emb_{i}'] = test_data['embeddings'].apply(lambda x: x[i])\n",
    "\n",
    "# Drop the original embeddings column and other non-feature columns\n",
    "data.drop(['embeddings', 'sentence', 'id', 'difficulty'], axis=1, inplace=True)\n",
    "test_data.drop(['embeddings', 'sentence', 'id'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   difficulty_encoded  LEN       AWL       TTR   ASL  AVPS  ASL.AVPS  \\\n",
      "0                   4   44  4.954545  0.704545  44.0   4.0     176.0   \n",
      "1                   0   14  3.642857  1.000000  14.0   2.0      28.0   \n",
      "2                   0   14  3.857143  0.928571  14.0   1.0      14.0   \n",
      "3                   0    9  3.666667  1.000000   9.0   1.0       9.0   \n",
      "4                   2   39  4.564103  0.794872  39.0   4.0     156.0   \n",
      "\n",
      "        mtld  num_subordinate_clauses  \n",
      "0  44.888889                        0  \n",
      "1  54.880000                        0  \n",
      "2  27.440000                        0  \n",
      "3   8.000000                        0  \n",
      "4  28.495275                        0  \n"
     ]
    }
   ],
   "source": [
    "#print(test_data.info(), data.info())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data for training and validation\n",
    "X = data.drop('difficulty_encoded', axis=1)\n",
    "y = data['difficulty_encoded']\n",
    "\n",
    "# Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning, training and validation of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END .................................C=0.1, gamma=scale; total time=   1.6s\n",
      "[CV] END ..................................C=0.1, gamma=auto; total time=   1.6s\n",
      "[CV] END ..................................C=0.1, gamma=auto; total time=   1.6s\n",
      "[CV] END ..................................C=0.1, gamma=auto; total time=   1.8s\n",
      "[CV] END .................................C=0.1, gamma=scale; total time=   1.8s\n",
      "[CV] END .................................C=0.1, gamma=scale; total time=   1.8s\n",
      "[CV] END .................................C=0.1, gamma=scale; total time=   2.0s\n",
      "[CV] END .................................C=0.1, gamma=scale; total time=   2.1s\n",
      "[CV] END ..................................C=0.1, gamma=auto; total time=   1.6s\n",
      "[CV] END ..................................C=0.1, gamma=auto; total time=   1.8s\n",
      "[CV] END ...................................C=1, gamma=scale; total time=   1.9s\n",
      "[CV] END ...................................C=1, gamma=scale; total time=   1.7s\n",
      "[CV] END ...................................C=1, gamma=scale; total time=   1.8s\n",
      "[CV] END ...................................C=1, gamma=scale; total time=   1.8s\n",
      "[CV] END ...................................C=1, gamma=scale; total time=   1.9s\n",
      "[CV] END ....................................C=1, gamma=auto; total time=   1.9s\n",
      "[CV] END ....................................C=1, gamma=auto; total time=   1.5s\n",
      "[CV] END ....................................C=1, gamma=auto; total time=   1.7s\n",
      "[CV] END ....................................C=1, gamma=auto; total time=   1.6s\n",
      "[CV] END ....................................C=1, gamma=auto; total time=   1.8s\n",
      "[CV] END ..................................C=10, gamma=scale; total time=   2.0s\n",
      "[CV] END ..................................C=10, gamma=scale; total time=   1.9s\n",
      "[CV] END ..................................C=10, gamma=scale; total time=   1.7s\n",
      "[CV] END ..................................C=10, gamma=scale; total time=   2.3s\n",
      "[CV] END ..................................C=10, gamma=scale; total time=   2.4s\n",
      "[CV] END ...................................C=10, gamma=auto; total time=   1.9s\n",
      "[CV] END ...................................C=10, gamma=auto; total time=   1.8s\n",
      "[CV] END ...................................C=10, gamma=auto; total time=   2.0s\n",
      "[CV] END ...................................C=10, gamma=auto; total time=   1.9s\n",
      "[CV] END ...................................C=10, gamma=auto; total time=   1.8s\n",
      "[CV] END .................................C=100, gamma=scale; total time=   3.6s\n",
      "[CV] END .................................C=100, gamma=scale; total time=   4.0s\n",
      "[CV] END .................................C=100, gamma=scale; total time=   3.5s\n",
      "[CV] END .................................C=100, gamma=scale; total time=   3.9s\n",
      "[CV] END .................................C=100, gamma=scale; total time=   3.4s\n",
      "[CV] END ..................................C=100, gamma=auto; total time=   3.5s\n",
      "[CV] END ..................................C=100, gamma=auto; total time=   3.3s\n",
      "[CV] END ..................................C=100, gamma=auto; total time=   3.3s\n",
      "[CV] END ..................................C=100, gamma=auto; total time=   2.2s\n",
      "[CV] END ..................................C=100, gamma=auto; total time=   2.0s\n",
      "Best parameters found:  {'C': 10, 'gamma': 'scale'}\n",
      "Classification Report on Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82        12\n",
      "           1       0.50      0.71      0.59         7\n",
      "           2       0.40      0.22      0.29         9\n",
      "           3       0.38      0.71      0.50         7\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.67      0.18      0.29        11\n",
      "\n",
      "    accuracy                           0.48        48\n",
      "   macro avg       0.48      0.43      0.41        48\n",
      "weighted avg       0.58      0.48      0.48        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'gamma': ['scale', 'auto'],  # Kernel coefficient\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object for an SVM with RBF kernel\n",
    "grid_search = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Use the best estimator for validation\n",
    "best_svm = grid_search.best_estimator_\n",
    "\n",
    "# Classification Metrics on Validation Set\n",
    "val_predictions = best_svm.predict(X_val)\n",
    "print(\"Classification Report on Validation Set:\")\n",
    "print(classification_report(y_val, val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/nathan/OneDrive/GitHub/Nvidia/Code/Model_Enhanced_training.ipynb Cell 9\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/Nvidia/Code/Model_Enhanced_training.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X_test_scaled \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(X_test)  \u001b[39m# Use the same scaler as for the training data\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/Nvidia/Code/Model_Enhanced_training.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Make predictions on test data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/Nvidia/Code/Model_Enhanced_training.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m test_predictions \u001b[39m=\u001b[39m best_svm\u001b[39m.\u001b[39mpredict(X_test_scaled)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/Nvidia/Code/Model_Enhanced_training.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Display predictions for test data\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nathan/OneDrive/GitHub/Nvidia/Code/Model_Enhanced_training.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, prediction \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(test_predictions):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_svm' is not defined"
     ]
    }
   ],
   "source": [
    "# Prepare test data (for which we don't have labels)\n",
    "X_test = test_data\n",
    "X_test_scaled = scaler.transform(X_test)  # Use the same scaler as for the training data\n",
    "\n",
    "# Make predictions on test data\n",
    "test_predictions = best_svm.predict(X_test_scaled)\n",
    "\n",
    "# Display predictions for test data\n",
    "for idx, prediction in enumerate(test_predictions):\n",
    "    print(f\"Test Data ID {idx}: Predicted Difficulty: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to Nvidia_submission.csv\n"
     ]
    }
   ],
   "source": [
    "cefr_mapping = {0: 'A1', 1: 'A2', 2: 'B1', 3: 'B2', 4: 'C1', 5: 'C2'}\n",
    "\n",
    "# Re-read the test_data to get the 'id' column back\n",
    "test_data = pd.read_csv('/home/nathan/OneDrive/GitHub/Nvidia/data/Cleaned_Enhanced_test.csv')\n",
    "\n",
    "# Apply the mapping to your predictions\n",
    "test_data['difficulty'] = test_predictions\n",
    "test_data['difficulty'] = test_data['difficulty'].map(cefr_mapping)\n",
    "\n",
    "# Save the 'id' and 'CEFR_difficulty' columns to a new CSV file\n",
    "test_data[['id', 'difficulty']].to_csv('Nvidia_submission.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to Nvidia_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
